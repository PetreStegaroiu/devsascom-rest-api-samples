{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Import, publish and run projects in K8s clusters\\n\",\n",
    "                \"This notebook leverages the IOT ESP API to create and publish projects into ESP.\\n\",\n",
    "                \"\\n\",\n",
    "                \"Pre-requisite: This example will assume that at same level as this Jupyter Notebook there is an *xml_projects* folder with XML files representing proejcts the user wants to import and publish to ESP.\\n\",\n",
    "                \"\\n\",\n",
    "                \"In this notebook we will loop through all XML projects in xml_projects folder and do the following:\\n\",\n",
    "                \"1. Check if projects have already been imported\\n\",\n",
    "                \"2. If yes, import it using next version number. Otherwise import it normally with version 1 \\n\",\n",
    "                \"3. Make project public so all users can see it\\n\",\n",
    "                \"4. Publish project\\n\",\n",
    "                \"5. Synchronize projects from Studio to ESM\\n\",\n",
    "                \"6. Create ESM Deployment Cluster on which to run the projects\\n\",\n",
    "                \"7. Start projets on K8s cluster on ESM\\n\",\n",
    "                \"\\n\",\n",
    "                \"   \\n\",\n",
    "                \"Note: Please make sure you run [Imports and Global Variables](#imports) before executing anything else in this notebook. Also ensure you are authenticated by running [Get Access Token](#authentication).\\n\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"## Imports and Global Variables <a id='imports'></a>\\n\",\n",
    "                \"Run this cell before any of the others as it imports packages and sets variables that will be used throughout the notebook.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 55,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Server: acme.kc4.ingress-nginx.espsc-kc5-m1.espstudio.sashq-d.openstack.sas.com\\n\",\n",
    "                        \"Username: fsduser\\n\",\n",
    "                        \"Password: Mercury7\\n\",\n",
    "                        \"ESM Deployment Cluster Name: test\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"import requests\\n\",\n",
    "                \"import xml.etree.ElementTree as ET\\n\",\n",
    "                \"import os\\n\",\n",
    "                \"import json\\n\",\n",
    "                \"import time\\n\",\n",
    "                \"import sys\\n\",\n",
    "                \"from urllib3.exceptions import InsecureRequestWarning\\n\",\n",
    "                \"\\n\",\n",
    "                \"\\n\",\n",
    "                \"def bootstrap_server_and_credentials():\\n\",\n",
    "                \"    global server, username, password, chosen_deployment_name\\n\",\n",
    "                \"    server = \\\"acme.kc4.ingress-nginx.espsc-kc5-m1.espstudio.sashq-d.openstack.sas.com\\\"\\n\",\n",
    "                \"    username = \\\"fsduser\\\"\\n\",\n",
    "                \"    password = \\\"Mercury7\\\"\\n\",\n",
    "                \"    chosen_deployment_name = \\\"test\\\"\\n\",\n",
    "                \"    if len(sys.argv) > 3:\\n\",\n",
    "                \"        server = sys.argv[1]\\n\",\n",
    "                \"        username = sys.argv[2]\\n\",\n",
    "                \"        password = sys.argv[3]\\n\",\n",
    "                \"\\n\",\n",
    "                \"    print('Server: ' + server)\\n\",\n",
    "                \"    print('Username: ' + username)\\n\",\n",
    "                \"    print('Password: ' + password, flush=True)\\n\",\n",
    "                \"    print('ESM Deployment Cluster Name: ' + chosen_deployment_name, flush=True)\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Suppress ssl warnings caused by verify=False\\n\",\n",
    "                \"requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\\n\",\n",
    "                \"bootstrap_server_and_credentials()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Get Access token <a id='authentication'></a>\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 56,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"eyJhbGciOiJSUzI1NiIsImprdSI6Imh0dHBzOi8vbG9jYWxob3N0L1NBU0xvZ29uL3Rva2VuX2tleXMiLCJraWQiOiJsZWdhY3ktdG9rZW4ta2V5IiwidHlwIjoiSldUIn0.eyJqdGkiOiI5ZTNjMWRlMWFlNDI0ZTgxYTBiMGE0YjRhNjYyNDhmNyIsImF1dGhvcml0aWVzIjpbIlZpeWFTQVNBZG1pbnMiLCJzdmlkZXZvcHMiLCJzdml2bXVzZXJzIiwiaW50Y2Fjb2Rlc2lnbmluZyIsInVuaXhfciZkIiwiVVNTQVMiLCJyY2ktY2lycnVzLWRldiIsImludGNhd2ViY2VydHJlcSIsIm9wZW5zdGFja3VzZXJzIiwicmNpLWNsdXN0ZXJkZXZtb2RlIiwiaW50Y2F1c2VycyJdLCJleHRfaWQiOiJjbj1STVMgRlNEIFByb2R1Y3RzIFVzZXIsb3U9R2VuZXJpYyBhbmQgU2hhcmVkIEFjY291bnRzLG91PUFkbWluLGRjPW5hLGRjPVNBUyxkYz1jb20iLCJzdWIiOiJlYTY1MTZlMi0wMTJiLTQ0MTktOWJhMS1kMTY3MWZmNjc2ZDAiLCJzY29wZSI6WyJvcGVuaWQiLCJ1YWEudXNlciJdLCJjbGllbnRfaWQiOiJzYXMuZWMiLCJjaWQiOiJzYXMuZWMiLCJhenAiOiJzYXMuZWMiLCJncmFudF90eXBlIjoicGFzc3dvcmQiLCJ1c2VyX2lkIjoiZWE2NTE2ZTItMDEyYi00NDE5LTliYTEtZDE2NzFmZjY3NmQwIiwib3JpZ2luIjoibGRhcCIsInVzZXJfbmFtZSI6ImZzZHVzZXIiLCJlbWFpbCI6ImZzZHVzZXJAdXNlci5mcm9tLmxkYXAuY2YiLCJhdXRoX3RpbWUiOjE3MTQwNTIwODAsInJldl9zaWciOiI5Njg4NWFlNiIsImlhdCI6MTcxNDA1MjA4MCwiZXhwIjoxNzE0MDU1NjgwLCJpc3MiOiJodHRwOi8vbG9jYWxob3N0L1NBU0xvZ29uL29hdXRoL3Rva2VuIiwiemlkIjoidWFhIiwiYXVkIjpbInVhYSIsIm9wZW5pZCIsInNhcy5lYyJdfQ.QY5XfQBtzrN2Wg_sKv3w17qvZWmPz6otR4z89gSC8ZkRppMXdLqaMLwpKLlCsBAznGokrKtVklnMC24JS2ocm-001zWrgl3Crjz0Nm8OmkmQJfyeNBoQfqz_krx3qRNvgLF6ziIDv8zZvS3_1t__9fDKxfFUQ0MQQWP0zAqwteSrqcOp2STyvVNIGf0fPF7HAHgp4xrUmMZb0XyZ4sakPioOoaXTKgumMpPpefU_P6v81HWJCAL_L_0folsv-YById-9KZXF4VadtR2E8t6awdLQ9zpFrjecpuAevO6CcV-9efGvYcb0RLxevUmJ-iEnx84aPiZP06Oldq0lWdvrmw\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"def get_access_token():\\n\",\n",
    "                \"    body = {'grant_type': 'password', 'username': username, 'password': password}\\n\",\n",
    "                \"    headers = {'Content-Type': 'application/x-www-form-urlencoded', 'Authorization': 'Basic c2FzLmVjOg=='}\\n\",\n",
    "                \"    access_token_response = requests.post('http://' + server + '/SASLogon/oauth/token', data=body, headers=headers,\\n\",\n",
    "                \"                                          verify=False)\\n\",\n",
    "                \"    return access_token_response.json()[\\\"access_token\\\"]\\n\",\n",
    "                \"\\n\",\n",
    "                \"access_token = get_access_token()\\n\",\n",
    "                \"print(access_token)\\n\",\n",
    "                \"headers = {\\\"Content-Type\\\": \\\"application/json\\\", \\\"Authorization\\\": \\\"Bearer \\\" + access_token}\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to get ESP Projects\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 12,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def get_projects():\\n\",\n",
    "                \"    projects = []\\n\",\n",
    "                \"    get_projects_response = requests.get(\\n\",\n",
    "                \"        'http://' + server + '/SASEventStreamProcessingStudio/esp-project', headers=headers, verify=False)\\n\",\n",
    "                \"    if get_projects_response.status_code == 200:\\n\",\n",
    "                \"        projects = get_projects_response.json()[\\\"items\\\"]\\n\",\n",
    "                \"    return projects\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to import project to ESP Studio\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 13,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def import_project_to_studio(project_body):\\n\",\n",
    "                \"    project_id = \\\"\\\"\\n\",\n",
    "                \"    import_project_response = requests.post('http://' + server + '/SASEventStreamProcessingStudio/esp-project',\\n\",\n",
    "                \"                                            data=json.dumps(project_body), headers=headers, verify=False)\\n\",\n",
    "                \"    if import_project_response.status_code == 200:\\n\",\n",
    "                \"        project_id = import_project_response.json()[\\\"flowId\\\"]\\n\",\n",
    "                \"        print('success, project_id=' + project_id)\\n\",\n",
    "                \"    return project_id\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to get next version number of a project\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 14,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def get_next_project_version(project_id):\\n\",\n",
    "                \"    version = 2\\n\",\n",
    "                \"    get_next_version_response = requests.get(\\n\",\n",
    "                \"        'http://' + server + '/SASEventStreamProcessingStudio/project-versions/projects/' + project_id + '/nextVersion',\\n\",\n",
    "                \"        headers=headers, verify=False)\\n\",\n",
    "                \"    if get_next_version_response.status_code == 200:\\n\",\n",
    "                \"        version = get_next_version_response.json()[\\\"major\\\"]\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        print('Failed to get next version')\\n\",\n",
    "                \"        print(get_next_version_response)\\n\",\n",
    "                \"    return version\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to make project public - by default it is private and hidden from other users\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 15,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def make_project_public(project_id):\\n\",\n",
    "                \"    requests.patch('http://' + server + '/SASEventStreamProcessingStudio/esp-project/'\\n\",\n",
    "                \"                   + project_id + '/authorization?private=false',\\n\",\n",
    "                \"                   headers={'Authorization': 'Bearer ' + access_token}, verify=False)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to create expected project model to be published\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 25,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def create_publish_project_body(project_body, version):\\n\",\n",
    "                \"    project_body[\\\"name\\\"] = project_body[\\\"friendlyName\\\"]\\n\",\n",
    "                \"    project_body[\\\"description\\\"] = \\\"\\\"\\n\",\n",
    "                \"    project_body[\\\"friendlyName\\\"] = None\\n\",\n",
    "                \"    project_body[\\\"majorVersion\\\"] = str(version)\\n\",\n",
    "                \"    project_body[\\\"minorVersion\\\"] = \\\"0\\\"\\n\",\n",
    "                \"    project_body[\\\"version\\\"] = str(version) + '.0'\\n\",\n",
    "                \"    project_body[\\\"versionNotes\\\"] = \\\"notes\\\"\\n\",\n",
    "                \"    project_body[\\\"uploadedBy\\\"] = username\\n\",\n",
    "                \"    project_body[\\\"modifiedBy\\\"] = username\\n\",\n",
    "                \"    epoch_time = int(time.time())\\n\",\n",
    "                \"    project_body[\\\"uploaded\\\"] = epoch_time\\n\",\n",
    "                \"    project_body[\\\"modified\\\"] = epoch_time + 10\\n\",\n",
    "                \"    project_body[\\\"isDeployable\\\"] = False\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to publish project\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 26,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def publish_project(project_id, project_body, version):\\n\",\n",
    "                \"    folder_id = \\\"\\\"\\n\",\n",
    "                \"    create_publish_project_body(project_body, version)\\n\",\n",
    "                \"    publish_project_response = requests.post(\\n\",\n",
    "                \"        'http://' + server + '/SASEventStreamProcessingStudio/project-versions/projects/' + project_id,\\n\",\n",
    "                \"        data=json.dumps(project_body), headers=headers, verify=False)\\n\",\n",
    "                \"\\n\",\n",
    "                \"    if publish_project_response.status_code == 200:\\n\",\n",
    "                \"        folder_id = publish_project_response.json()[\\\"folderId\\\"]\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        print('PUBLISH FAILED')\\n\",\n",
    "                \"        print(publish_project_response)\\n\",\n",
    "                \"        print('Version:' + str(version))\\n\",\n",
    "                \"    return folder_id\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to synchronize projects from Studio to ESM\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 27,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def synchronize_project_for_ESM(folder_id):\\n\",\n",
    "                \"    success = False\\n\",\n",
    "                \"    synchronize_project_response = requests.post(\\n\",\n",
    "                \"        'http://' + server + '/SASEventStreamProcessingStudio/project-versions/projects/synchronize/' + folder_id,\\n\",\n",
    "                \"        data=folder_id, headers=headers, verify=False)\\n\",\n",
    "                \"\\n\",\n",
    "                \"    if synchronize_project_response.status_code == 200:\\n\",\n",
    "                \"        success = True\\n\",\n",
    "                \"    return success\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to get deployment details needed to start K8s cluster on ESM\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 45,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def get_deployment_details():\\n\",\n",
    "                \"    success = True\\n\",\n",
    "                \"    deployment_id = ''\\n\",\n",
    "                \"    deployment_name = ''\\n\",\n",
    "                \"    projects_running_on_deployment = []\\n\",\n",
    "                \"    deployments_response = requests.get(\\\"http://\\\" + server + \\\"/SASEventStreamManager/deployment?noDetails=false\\\",\\n\",\n",
    "                \"                                        headers=headers, verify=False)\\n\",\n",
    "                \"\\n\",\n",
    "                \"    if deployments_response.status_code != 200:\\n\",\n",
    "                \"        print(\\\"Could not find any deployments\\\", deployments_response.text)\\n\",\n",
    "                \"        success = False\\n\",\n",
    "                \"\\n\",\n",
    "                \"    # Here we try to start clusters against the hard-coded deployment name\\n\",\n",
    "                \"    # if it does not exist, it will spin off cluster against 1st cluster\\n\",\n",
    "                \"    deployment_items = deployments_response.json()[\\\"items\\\"]\\n\",\n",
    "                \"    if len(deployment_items) > 0:\\n\",\n",
    "                \"        deployment_id = deployment_items[0][\\\"uuid\\\"]\\n\",\n",
    "                \"        deployment_name = deployment_items[0][\\\"label\\\"]\\n\",\n",
    "                \"        projects_running_on_deployment = get_project_names_from_deployment(deployment_items[0])\\n\",\n",
    "                \"        \\n\",\n",
    "                \"        for deployment in deployment_items:\\n\",\n",
    "                \"            if deployment[\\\"type\\\"] == \\\"cluster\\\" and deployment[\\\"label\\\"] == chosen_deployment_name:\\n\",\n",
    "                \"                deployment_id = deployment[\\\"uuid\\\"]\\n\",\n",
    "                \"                deployment_name = deployment[\\\"label\\\"]\\n\",\n",
    "                \"                projects_running_on_deployment = get_project_names_from_deployment(deployment)\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        print(\\\"Could not find any deployments\\\", deployments_response.text)\\n\",\n",
    "                \"        success = False\\n\",\n",
    "                \"\\n\",\n",
    "                \"    return success, deployment_id, deployment_name, projects_running_on_deployment\\n\",\n",
    "                \"\\n\",\n",
    "                \"def get_project_names_from_deployment(deployment):\\n\",\n",
    "                \"    project_names = []\\n\",\n",
    "                \"    for server in deployment[\\\"servers\\\"]:\\n\",\n",
    "                \"        project_names = project_names + list(map(lambda project: project[\\\"name\\\"], server[\\\"projects\\\"]))\\n\",\n",
    "                \"    return project_names\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Function to start K8s cluster on ESM\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 48,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"def start_k8s_cluster(k8s_project_body):\\n\",\n",
    "                \"    success, deployment_id, deployment_name, projects_running_on_deployment = get_deployment_details()\\n\",\n",
    "                \"\\n\",\n",
    "                \"    if k8s_project_body[\\\"name\\\"] in projects_running_on_deployment:\\n\",\n",
    "                \"        print(\\\"Project \\\" + k8s_project_body[\\\"name\\\"] + \\\" is already running on deployment \\\" + deployment_name +\\\".\\\")\\n\",\n",
    "                \"    elif success:\\n\",\n",
    "                \"        # Here are the deployment settings hard-coded for all projects\\n\",\n",
    "                \"        k8s_deployment_settings = {\\n\",\n",
    "                \"            \\\"persistentVolumeClaim\\\": \\\"sas-event-stream-processing-studio-app\\\",\\n\",\n",
    "                \"            \\\"requestsMemory\\\": \\\"1Gi\\\",\\n\",\n",
    "                \"            \\\"requestsCpu\\\": 1,\\n\",\n",
    "                \"            \\\"requestsGpu\\\": \\\"0\\\",\\n\",\n",
    "                \"            \\\"limitsMemory\\\": \\\"1Gi\\\",\\n\",\n",
    "                \"            \\\"limitsCpu\\\": 1,\\n\",\n",
    "                \"            \\\"limitsGpu\\\": \\\"0\\\",\\n\",\n",
    "                \"            \\\"minReplicas\\\": 1,\\n\",\n",
    "                \"            \\\"maxReplicas\\\": 1,\\n\",\n",
    "                \"            \\\"useLoadBalancer\\\": False,\\n\",\n",
    "                \"            \\\"loadBalancingPolicy\\\": \\\"none\\\",\\n\",\n",
    "                \"            \\\"averageUtilization\\\": \\\"50\\\",\\n\",\n",
    "                \"            \\\"loadBalancerTargetsList\\\": []\\n\",\n",
    "                \"        }\\n\",\n",
    "                \"        k8s_cluster_body = {\\n\",\n",
    "                \"            \\\"distinguisher\\\": deployment_name,\\n\",\n",
    "                \"            \\\"esmDeploymentId\\\": deployment_id,\\n\",\n",
    "                \"            \\\"gpuReliant\\\": False,\\n\",\n",
    "                \"            \\\"loadOnly\\\": False,\\n\",\n",
    "                \"            \\\"project\\\": k8s_project_body,\\n\",\n",
    "                \"            \\\"settings\\\": k8s_deployment_settings\\n\",\n",
    "                \"        }\\n\",\n",
    "                \"\\n\",\n",
    "                \"        response = requests.post(\\\"http://\\\" + server + \\\"/SASEventStreamManager/server/cluster\\\",\\n\",\n",
    "                \"                                 data=json.dumps(k8s_cluster_body), headers=headers, verify=False)\\n\",\n",
    "                \"        if response.status_code != 200:\\n\",\n",
    "                \"            print(\\\"error creating cluster\\\", response.text)\\n\",\n",
    "                \"        else:\\n\",\n",
    "                \"            print(\\\"Project \\\" + k8s_project_body[\\\"name\\\"], \\\" successfully started K8s pod in deployment: \\\" + deployment_name)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Create ESM Deployment for projects to run against\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 58,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Deployment test already exists, we can proceed to start the projects\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"def create_ESM_cluster_deployment():\\n\",\n",
    "                \"    deployment_alread_exists_error = 'A deployment named \\\"' + chosen_deployment_name + '\\\" already exists'\\n\",\n",
    "                \"    deployment_body = {\\n\",\n",
    "                \"        \\\"name\\\": chosen_deployment_name,\\n\",\n",
    "                \"        \\\"type\\\": \\\"cluster\\\"\\n\",\n",
    "                \"    }\\n\",\n",
    "                \"    response = requests.post('http://' + server + '/SASEventStreamManager/deployment',\\n\",\n",
    "                \"                                            data=json.dumps(deployment_body), headers=headers, verify=False)\\n\",\n",
    "                \"    if deployment_alread_exists_error in response.text:\\n\",\n",
    "                \"        print (\\\"Deployment \\\" + chosen_deployment_name + \\\" already exists, we can proceed to start the projects\\\")\\n\",\n",
    "                \"    elif response.status_code != 201:\\n\",\n",
    "                \"        print(\\\"error creating ESM cluster deployment\\\", response.text)\\n\",\n",
    "                \"\\n\",\n",
    "                \"create_ESM_cluster_deployment()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Loop through all XML projects in xml_projects folder and do the following\\n\",\n",
    "                \"1. Check if projects have already been imported\\n\",\n",
    "                \"2. If yes, import it using next version number. Otherwise import it normally with version 1 \\n\",\n",
    "                \"3. Make project public so all users can see it\\n\",\n",
    "                \"4. Publish project\\n\",\n",
    "                \"5. Synchronize projects from Studio to ESM\\n\",\n",
    "                \"6. Create ESM Deployment Cluster on which to run the projects\\n\",\n",
    "                \"7. Start projets on K8s cluster on ESM\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 50,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"\\n\",\n",
    "                        \"example_project is already imported\\n\",\n",
    "                        \"Creating new project version: 9\\n\",\n",
    "                        \"example_project.xml successfully published\\n\",\n",
    "                        \"Project example_project is already running on deployment test.\\n\",\n",
    "                        \"\\n\",\n",
    "                        \"star_wars is already imported\\n\",\n",
    "                        \"Creating new project version: 7\\n\",\n",
    "                        \"star_wars.xml successfully published\\n\",\n",
    "                        \"Project star_wars is already running on deployment test.\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"def import_and_publish_xml_files():\\n\",\n",
    "                \"    current_dir = os.getcwd() + \\\"/xml_projects\\\"\\n\",\n",
    "                \"    projects = get_projects()\\n\",\n",
    "                \"    for file_name in os.listdir(current_dir):\\n\",\n",
    "                \"        print()\\n\",\n",
    "                \"        if not file_name.endswith('.xml'): continue\\n\",\n",
    "                \"        version = 1\\n\",\n",
    "                \"        project_id = None\\n\",\n",
    "                \"        xml_file_path = os.path.join(current_dir, file_name)\\n\",\n",
    "                \"        project_name = get_project_name_from_xml(xml_file_path)\\n\",\n",
    "                \"        data = open(xml_file_path, \\\"r\\\").read()\\n\",\n",
    "                \"        project_body = {'friendlyName': project_name, 'xml': data}\\n\",\n",
    "                \"\\n\",\n",
    "                \"        if projects:\\n\",\n",
    "                \"            project_that_matches_xml_name = None\\n\",\n",
    "                \"            for project in projects:\\n\",\n",
    "                \"                if project['friendlyName'] == project_name:\\n\",\n",
    "                \"                    project_that_matches_xml_name = project\\n\",\n",
    "                \"                    break\\n\",\n",
    "                \"\\n\",\n",
    "                \"            if project_that_matches_xml_name:\\n\",\n",
    "                \"                print(project_name + ' is already imported')\\n\",\n",
    "                \"                project_id = project_that_matches_xml_name['flowId']\\n\",\n",
    "                \"                version = get_next_project_version(project_id)\\n\",\n",
    "                \"                print('Creating new project version: ' + str(version))\\n\",\n",
    "                \"\\n\",\n",
    "                \"        if not bool(project_id):\\n\",\n",
    "                \"            print('Importing ' + project_name)\\n\",\n",
    "                \"            project_id = import_project_to_studio(project_body)\\n\",\n",
    "                \"            make_project_public(project_id)\\n\",\n",
    "                \"\\n\",\n",
    "                \"        folder_id = publish_project(project_id, project_body, version)\\n\",\n",
    "                \"\\n\",\n",
    "                \"        synchronize_project_for_ESM(folder_id)\\n\",\n",
    "                \"\\n\",\n",
    "                \"        if project_id:\\n\",\n",
    "                \"            print(file_name + ' successfully published', flush=True)\\n\",\n",
    "                \"        else:\\n\",\n",
    "                \"            print(file_name + ' failed to publish', flush=True)\\n\",\n",
    "                \"\\n\",\n",
    "                \"        k8s_project_body = {\\\"id\\\": project_id, \\\"name\\\": project_name, \\\"version\\\": version}\\n\",\n",
    "                \"        start_k8s_cluster(k8s_project_body)\\n\",\n",
    "                \"\\n\",\n",
    "                \"def get_project_name_from_xml(xml_file_path):\\n\",\n",
    "                \"    tree = ET.parse(xml_file_path)\\n\",\n",
    "                \"    root = tree.getroot()\\n\",\n",
    "                \"    project_name = root.attrib['name']\\n\",\n",
    "                \"    return project_name\\n\",\n",
    "                \"\\n\",\n",
    "                \"\\n\",\n",
    "                \"\\n\",\n",
    "                \"import_and_publish_xml_files()\\n\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": null,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": []\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3 (ipykernel)\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"codemirror_mode\": {\n",
    "                \"name\": \"ipython\",\n",
    "                \"version\": 3\n",
    "            },\n",
    "            \"file_extension\": \".py\",\n",
    "            \"mimetype\": \"text/x-python\",\n",
    "            \"name\": \"python\",\n",
    "            \"nbconvert_exporter\": \"python\",\n",
    "            \"pygments_lexer\": \"ipython3\",\n",
    "            \"version\": \"3.11.2\"\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}